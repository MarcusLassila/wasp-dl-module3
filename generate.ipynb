{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f98ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_image(images, rescale_method=\"clamp\", name=\"temp_image\"):\n",
    "    # Create the 4x4 grid\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img, ax in zip(images, axes):\n",
    "        if rescale_method == \"tanh\":\n",
    "            img = torch.tanh(img)\n",
    "        elif rescale_method == \"clamp\":\n",
    "            img = torch.clamp(img, -1.0, 1.0)\n",
    "        elif rescale_method == \"none\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported rescale method\")\n",
    "        img = (img + 1) / 2\n",
    "        img = img.permute(1, 2, 0)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    Path(\"./images\").mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(f\"./images/{name}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "images = torch.load(\"./images/image_batch.pth\", map_location=\"cpu\")\n",
    "plot_image(images[:16], rescale_method=\"clamp\", name=f\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc082fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import vae\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "checkpoint = torch.load(f\"../trained_models/VAE_model.pth\", map_location=\"cpu\")\n",
    "model = vae.VAE(\n",
    "    in_channels=checkpoint[\"in_channels\"],\n",
    "    in_dim=checkpoint[\"in_dim\"],\n",
    "    latent_dim=checkpoint[\"latent_dim\"],\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "batch_size = 16\n",
    "samples = model.sample(batch_size)\n",
    "samples = samples.reshape(batch_size, 1, 28, 28)\n",
    "\n",
    "plot_image(samples[:16], rescale_method=\"clamp\", name=f\"vae_images\")\n",
    "\n",
    "train_loss = checkpoint[\"train_loss\"]\n",
    "val_loss = checkpoint[\"val_loss\"]\n",
    "assert len(train_loss) == len(val_loss)\n",
    "n_epochs = [*range(len(train_loss))]\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.plot(n_epochs, train_loss, label=\"train loss\")\n",
    "plt.plot(n_epochs, val_loss, label=\"val loss\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
